\chapter{Text Data}\label{CHAPTER:XML}
<<echo = FALSE, message = FALSE>>=
library(ggplot2)
@
Many applications require the ability to manipulate and process text data. For example, an email spam filter takes as its input various features of email such as the sender, words in the subject, words in the body, the number and types of attachments, and so on. The filter then tries to build a classifier which can correctly classify a message as spam or not spam (aka ham). As another example, some works of literature, such as some of Shakespeare's plays or some of the Federalist papers, have disputed authorship. By analyzing word use across many documents, researchers try to determine the author of the disputed work.

Working with text data requires functions that will, for example, concatenate and split text strings, modify strings (e.g., converting to lower-case or removing vowels), count the number of characters in a string, and so on. In addition to being useful in such contexts, string manipulation is helpful more generally in R---for example, to effectively construct titles for graphics.

As with most tasks, there are a variety of ways to accomplish these text processing tasks in R. The base R package has functions which work with and modify text strings. Another useful package which approaches these tasks in a slightly different way is \verb+stringr+. As with graphics, we will focus mainly on one package to avoid confusion. In this case we will focus on the base R string processing functions, but will emphasize that \verb+stringr+ is also worth knowing.

The application to analyzing \emph{Moby Dick} below comes from the book \emph{Text Analysis with R for Students of Literature} by Matthew L. Jockers.

\section{Reading text data into R}
Often text data will not be in a rectangular format that is suitable for reading into a data frame. For example, an email used to help train a spam filter, or literary texts used to help determine authorship of a novel are certainly not of this form. Often when working with text data we want to read the whole text object into a single R vector. In this case either the \verb+scan+ function or the \verb+readLines+ function are useful. The \verb+readLines+ function is typically more efficient, but \verb+scan+ is much more flexible. 

As an example, consider the email file in Figure~\ref{FIG:SPAMAGAIN} and a plain text version of the novel \emph{Moby Dick} by Herman Melville, the beginning of which is displayed in Figure~\ref{FIG:MOBYDICK}. The email message is available at \url{http://blue.for.msu.edu/FOR875/data/email1.txt} while the novel is available at \url{http://blue.for.msu.edu/FOR875/data/mobydick.txt}. We will read these into R using \verb+scan+. 

\begin{figure}[h]
\begin{Verbatim}[fontsize = \small]
From safety33o@l11.newnamedns.com  Fri Aug 23 11:03:37 2002
Return-Path: <safety33o@l11.newnamedns.com>
Delivered-To: zzzz@localhost.example.com
Received: from localhost (localhost [127.0.0.1])
	by phobos.labs.example.com (Postfix) with ESMTP id 5AC994415F
	for <zzzz@localhost>; Fri, 23 Aug 2002 06:02:59 -0400 (EDT)
Received: from mail.webnote.net [193.120.211.219]
	by localhost with POP3 (fetchmail-5.9.0)
	for zzzz@localhost (single-drop); Fri, 23 Aug 2002 11:02:59 +0100 (IST)
Received: from l11.newnamedns.com ([64.25.38.81])
	by webnote.net (8.9.3/8.9.3) with ESMTP id KAA09379
	for <zzzz@example.com>; Fri, 23 Aug 2002 10:18:03 +0100
From: safety33o@l11.newnamedns.com
Date: Fri, 23 Aug 2002 02:16:25 -0400
Message-Id: <200208230616.g7N6GOR28438@l11.newnamedns.com>
To: kxzzzzgxlrah@l11.newnamedns.com
Reply-To: safety33o@l11.newnamedns.com
Subject: ADV: Lowest life insurance rates available!                                                   
moode

Lowest rates available for term life insurance! Take a moment 
and fill out our online form 
to see the low rate you qualify for. 
Save up to 70% from regular rates! Smokers accepted! 
http://www.newnamedns.com/termlife/ 
          
Representing quality nationwide carriers. Act now!
\end{Verbatim}
\caption{A spam email message}
\label{FIG:SPAMAGAIN}
\end{figure}

\begin{figure}[h]
\begin{Verbatim}[fontsize = \small]
The Project Gutenberg EBook of Moby Dick; or The Whale, by Herman Melville

This eBook is for the use of anyone anywhere at no cost and with
almost no restrictions whatsoever.  You may copy it, give it away or
re-use it under the terms of the Project Gutenberg License included
with this eBook or online at www.gutenberg.org


Title: Moby Dick; or The Whale

Author: Herman Melville

Last Updated: January 3, 2009
Posting Date: December 25, 2008 [EBook #2701]
Release Date: June, 2001

Language: English


*** START OF THIS PROJECT GUTENBERG EBOOK MOBY DICK; OR THE WHALE ***




Produced by Daniel Lazarus and Jonesey





MOBY DICK; OR THE WHALE

By Herman Melville
\end{Verbatim}
\caption{The beginning of a plain text file from Project Gutenberg containing the novel \emph{Moby Dick}}
\label{FIG:MOBYDICK}
\end{figure}

First, we read in the email message. The \verb+scan+ function has several possible arguments. For now the important arguments are the file to be read (the argument is named \verb+file+), the type of data in the file (the argument is named \verb+what+), and how the fields in the file are separated (the argument is named \verb+sep+). To illustrate the \verb+sep+ argument, the file will be read into R once with \verb+sep = ""+ indicating that the separator is whitespace, and once with \verb+sep = "\n"+ indicating that the separator is the newline character, i.e., each field in the file is a line.
<<ReadEmail, cache = TRUE>>=
u.email <- "http://blue.for.msu.edu/FOR875/data/email1.txt"
email1 <- scan(u.email, what = "character", sep = "")
length(email1)
email1[1:10]
email1 <- scan(u.email, what = "character", sep = "\n")
length(email1)
email1[1:10]
@

Note that when \verb+sep = ""+ was specified, every time whitespace was encountered R moved to a new element of the vector \verb+email1+, and this vector ultimately contained 133 elements. When \verb+sep = "\n"+ was specified, all the text before a newline was put into one element of the vector, which ended up with 26 elements.

The \verb+scan+ function is quite flexible. In fact, \verb+read.table+ uses \verb+scan+ to actually read in the data. Read the help file for \verb+scan+ if more information is desired. 

Next \emph{Moby Dick} is read in line by line. 
<<ReadMobyDick, cache=TRUE>>=
u.moby <- "http://blue.for.msu.edu/FOR875/data/mobydick.txt"
moby_dick <- scan(u.moby, what = "character", sep = "\n")
moby_dick[1:25]
@
You will notice that \verb+scan+ function ignored blank lines in the file. If it is important to preserve blank lines, the argument \verb+blank.lines.skip = FALSE+ can be supplied to \verb+scan+.

The file containing the novel contains some introductory and closing text that is not part of the original novel. If we are interested in Melville's writing, we should remove this text. By inspection we can discover that the novel's text begins at position 408 and ends at position 18576.
<<>>=
moby_dick <- moby_dick[408:18576]
length(moby_dick)
moby_dick[1:4]
moby_dick[18165:18169]
@

\section{The \texttt{paste} function}
The \verb+paste+ function concatenates vectors after (if necessary) converting the vectors to character. 
<<>>=
paste("Homer Simpson", "is", "Bart Simpson's", "father")
n <- 10
paste("The value of n is", n)
paste(c("pig", "dog"), 3)
@
By default the \verb+paste+ function separates the input vectors with a space. But other separators can be specified. 
<<>>=
paste("mail", "google", "com", sep=".")
paste("and", "or", sep = "/")
paste(c("dog", "cat", "horse", "human", "elephant"), "food")
@

Sometimes we want to take a character vector with $n$ elements and create a character vector with only one element, which contains all $n$ character strings. Setting the \verb+collapse+ argument to something other than the default \verb+NULL+ tells R we want to do this, and allows specification of the separator in the collapsed vector.

<<>>=
paste(c("one", "two", "three", "four", "five"), 
      c("six", "seven", "eight", "nine", "ten"))
paste(c("one", "two", "three", "four", "five"), 
      c("six", "seven", "eight", "nine", "ten"), collapse = ".")
paste(c("one", "two", "three", "four", "five"),  
      c("six", "seven", "eight", "nine", "ten"), collapse = "&&")
paste(c("one", "two", "three", "four", "five"),
      c("six", "seven", "eight", "nine", "ten"), collapse = " ")
@
In the example above by default \verb+paste+ created a vector with five elements, each containing one input string from the first input vector and one from the second vector, pasted together.  When a non \verb+NULL+ argument was specified for \verb+collapse+, the vector created had one element, with the pasted strings separated by that argument.\footnote{There is a somewhat subtle difference among the examples. If all the arguments are length one vectors, then \texttt{paste} by default returns a length one vector. But if one or more of the arguments have length greater than one, the default behavior of paste is to return a vector of length greater than one. The \texttt{collapse} argument changes this behavior.} 

Also don't forget that R ``recycles'' values from vectors if two or more different length vectors are provided as input.
<<>>=
paste(c("a", "b"), 1:10, sep = "")
paste(c("a", "b"), 1:9, sep = "")
@

Next, consider writing a function which simulates repeatedly tossing a coin $n$ times, counting the number of HEADS out of the $n$ tosses. For the first five repetitions of $n$ tosses, the function will print out the number of HEADS (for example if there are 7 HEADS in the $n=10$ tosses the function prints "The number of HEADS out of 10 tosses is 7." The function returns a histogram of the number of HEADS, with a title stating "Number of HEADS in ?? tosses" where ?? is replaced by the number of tosses. The \verb+paste+ function will help greatly.
<<cointoss>>=
coin_toss <- function(n=10, iter = 500){
  require(ggplot2)
  df <- data.frame(numheads = numeric(iter))
  for(i in 1:iter) {
    df$numheads[i] <- rbinom(1, n, 0.5)
    if(i <= 5) {
      print(paste("The number of HEADS out of", n, "tosses is", df$numheads[i]))}
  }
ggplot(data = df, aes(x = numheads)) + 
  geom_histogram(binwidth = 1) + 
  ggtitle(paste("Number of HEADS in", n, "tosses"))
}
coin_toss()
coin_toss(n = 25, iter=1000)
@

Let's now return to the object \verb+moby_dick+ that contains the text of the novel. If we want to analyze word choice, word frequency, etc., it would be helpful to form a vector in which each element is a word from the novel. One way to do this is to first paste the current version of the \verb+moby_dick+ variable into a new version which is one long vector with the lines pasted together. To illustrate, we will first do this with a much smaller object that shares the structure of \verb+moby_dick+.

<<>>=
small_novel <- c("First line", "Second somewhat longer line", 
                 "third line.")
small_novel
small_novel <- paste(small_novel, collapse=" ")
length(small_novel)
small_novel
@
Now we do the same with the actual novel.
<<>>=
moby_dick <- paste(moby_dick, collapse = " ")
length(moby_dick)
@
At this point \verb+moby_dick+ contains a single very long character string. Next we will separate this string into separate words and clean up the resulting vector a bit.

\section{More string processing functions}
Common string processing tasks include changing case between upper and lower, extracting and/or replacing substrings of a string, trimming a string to a specified width, counting the number of characters in a string, etc. 

\subsection*{\texttt{tolower} and \texttt{toupper}}
R contains functions \verb+tolower+ and \verb+toupper+ which very simply change the case of all characters in a string.
<<>>=
x <- "aBCdefG12#"
y <- x
tolower(x)
toupper(y)
@

If we are interested in frequencies of words in \emph{Moby Dick}, converting all the text to the same case makes sense, so for example the word ``the'' at the beginning of a sentence is not counted differently than the same word in the middle of a sentence.

<<>>=
moby_dick <- tolower(moby_dick)
@

\subsection*{\texttt{nchar} and \texttt{strsplit}}
The function \verb+nchar+ counts the number of characters in a string or strings.

<<>>=
nchar("dog")
nchar(c("dog", "cat", "horse", "elephant"))
nchar(c("dog", "cat", "horse", "elephant", NA, "goat"))
nchar(c("dog", "cat", "horse", "elephant", NA, "goat"), keepNA = FALSE)
nchar(moby_dick)
@
By default \verb+nchar+ returns NA for a missing value. If you want \verb+nchar+ to return 2 for a \verb+NA+ value, you can set \verb+keepNA = TRUE+.\footnote{It may be reasonable if the purpose of counting characters is to find out how much space to allocate for printing a vector of strings where the \texttt{NA} string will be printed.} 

The function \verb+strsplit+ splits the elements of a character vector. The function returns a list, and often the \verb+unlist+ function is useful to convert the list into an atomic vector. 

<<>>=
strsplit(c("mail.msu.edu", "mail.google.com", "www.amazon.com"),
         split = ".", fixed = TRUE)
unlist(strsplit(c("mail.msu.edu", "mail.google.com", "www.amazon.com"),
                split = ".", fixed = TRUE))
unlist(strsplit(c("dog", "cat", "pig", "horse"), 
                split = "o", fixed = TRUE))
@
Setting the argument \verb+fixed+ to \verb+TRUE+ tells R to match the value of \verb+split+ exactly when performing the split. The function can be much more powerful if the value of \verb+split+ is a \emph{regular expression}, which can for example ask for splits at any vowels, etc. We will not go in depth on Regular Expressions here, but we will make some use of regular expressions on a case-by-case basis prior to that. Regular expressions are very powerful, so if this chapter interests you, we suggest researching regular expressions on your own (as always there are plenty of free resources online). 
<<>>=
unlist(strsplit(c("dog", "cat", "pig", "horse", "rabbit"), 
                split = "[aeiou]"))
@
The regular expression \verb+[aeiou]+ represents any of the letters a, e, i, o, u. In general a string of characters enclosed in square brackets indicates any one character in the string.

<<>>=
unlist(strsplit(c("dog", "cat", "pig", "horse", "rabbit"), 
                split = "[aorb]"))
@
The regular expression \verb+[aorb]+ represents any of the letters a, o, r, b.

<<>>=
unlist(strsplit(c("a1c2b", "bbb2bc3f"), split = "[1-9]"))
@

The regular expression \verb+[1-9]+ represents any of the numbers 1, 2, 3, 4, 5, 6, 7, 8, 9.

<<>>=
unlist(strsplit(c("aBc1fGh", "1TyzaaG"), split = "[^a-z]"))
@
The regular expression \verb+[a-z]+ represents any lower case letter. The caret \verb+^+ in front of \verb+a-z+ indicates ``match any character \emph{except} those in the following string'' which in this case indicates ``match any character that is NOT a lower case letter.''

Recall that the \verb+moby_dick+ vector now contains one long character string which includes the entire text of the novel, and that we would like to split it into separate words. We now know how to do this using \verb+strsplit+ and a regular expression. First a smaller example.
<<>>=
unlist(strsplit(c("the rain", "in Spain stays mainly", "in", "the plain"), 
                split = "[^0-9A-Za-z]"))
unlist(strsplit(c("the rain", "in Spain stays mainly", "in", "the plain"), 
                split =" ", fixed = TRUE))
@
Look at the regular expression. The caret says ``match anything but'' and then \verb+0=9A-Za-z+ says ``any digit, any lower-case letter, and any upper-case letter.'' So the whole expression (including the fact that it is the value of the argument \verb+split+) says ``match anything but any digit, any lower-case letter, or any upper-case letter.''

Now we apply this to \verb+moby_dick+.
<<>>=
moby_dick <- unlist(strsplit(moby_dick, split = "[^0-9A-Za-z]"))
@
Let's see a bit of what we have.
<<>>=
moby_dick[1:50]
@
There is a small problem: Some of the ``words'' are blank. The following small example indicates why this happened.
<<>>=
unlist(strsplit(c("the rain", "in Spain    stays mainly", "in", "the plain"), split = "[^0-9A-Za-z]"))
@
It is not too hard to remove the blank words.
<<>>=
length(moby_dick)
not.blanks <- which(moby_dick != "")
moby_dick <- moby_dick[not.blanks]
length(moby_dick)
moby_dick[1:50]
@
(In this example it would have been more efficient to replace 
\begin{verbatim}
moby_dick <- unlist(strsplit(moby_dick, split = "[^0-9A-Za-z]"))
\end{verbatim}
by 
\begin{verbatim}
moby_dick2 <- unlist(strsplit(moby_dick, split = " ", fixed = TRUE))
\end{verbatim}
Then the second step of selecting the non-blank words would not have been necessary. But regular expressions will be essential going forward, so it was worthwhile using regular expressions even if they do not provide the most efficient method.)

\subsection*{\texttt{nchar} again}
Now that the vector \verb+moby_dick+ contains each word in the novel as a separate element, it is relatively easy to do some basic analyses. For example the \verb+nchar+ function can give us a count of the number of characters in each element of the vector, i.e., can give us the number of letters in each word in the novel.

<<>>=
moby_dick_nchar <- nchar(moby_dick)
moby_dick_nchar[1:50]
max(moby_dick_nchar)
ggplot(data = data.frame(nwords = moby_dick_nchar), aes(x = nwords)) + 
  geom_histogram(binwidth = 1, color = "black", fill = "white") + 
  ggtitle("Number of letters in words in Moby Dick") + 
  theme_bw()
@

<<echo = FALSE, eval = FALSE>>=
##There are a lot of numeric "words" in the vector
##Do we really want these in the file?
md <- sort(moby_dick)
md[1:1000]
@

<<>>=
moby_dick_word_table <- table(moby_dick)
moby_dick_word_table <- sort(moby_dick_word_table, decreasing = TRUE)
moby_dick_word_table[1:50]
@

\subsection*{\texttt{substr} and \texttt{strtrim}}
The \verb+substr+ function can be used to extract or replace substrings. The first argument is the string to be manipulated, and the second and third arguments specify the first and last elements of the string to be extracted or to be replaced.

<<>>=
x <- "Michigan"
substr(x, 3, 4)
substr(x, 3, 4) <- "CH"
x
x <- c("Ohio", "Michigan", "Illinois", "Wisconsin")
substr(x, 2,4)
substr(x, 2, 4) <- "$#&"
x
@

The \verb+strtrim+ function trims a character string to a specified length. 

<<>>=
strtrim("Michigan", 1)
strtrim("Michigan", 4)
strtrim("Michigan", 100)
strtrim(c("Ohio", "Michigan", "Illinois", "Wisconsin"), 3)
strtrim(c("Ohio", "Michigan", "Illinois", "Wisconsin"), c(3, 4, 5, 6))
@

\subsection*{\texttt{grep} and related functions}

The \verb+grep+ function searches for a specified pattern and returns either the locations where this pattern is found or the selected elements. The \verb+grepl+ function returns a logical vector rather than locations of elements.

Here are some examples. All use \verb+fixed = TRUE+ since at this point we are using fixed character strings rather than regular expressions.

<<>>=
grep("a", c("the rain", "in Spain    stays mainly", "in", "the plain"), 
     fixed = TRUE)
grep("a", c("the rain", "in Spain    stays mainly", "in", "the plain"), 
     fixed = TRUE, value = TRUE)
grepl("a", c("the rain", "in Spain    stays mainly", "in", "the plain"), 
      fixed = TRUE)
@

The \verb+sub+ and \verb+gsub+ functions replace a specified character string. The \verb+sub+ function only replaces the first occurrence, while \verb+gsub+ replaces all occurrences.

<<>>=
gsub("a", "?", c("the rain", "in Spain    stays mainly", "in", 
                 "the plain"), fixed = TRUE)
sub("a", "?", c("the rain", "in Spain    stays mainly", "in", 
                "the plain"), fixed = TRUE)
gsub("a", "???", c("the rain", "in Spain    stays mainly", "in", 
                   "the plain"), fixed = TRUE)
sub("a", "???", c("the rain", "in Spain    stays mainly", "in", 
                  "the plain"), fixed = TRUE)
@

\begin{hw}
{Learning objectives: read and write text data; concatenate text with the {\tt paste} function; analyze text with {\tt nchar}; practice with functions; manipulate strings with {\tt substr} and {\tt strtrim}.}
\end{hw}
